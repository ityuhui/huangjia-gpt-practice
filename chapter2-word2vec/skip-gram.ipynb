{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip Gram Word2Vec\n",
    "\n",
    "## Setup the environment\n",
    "\n",
    "Local-MacbookPro M1Pro\n",
    "\n",
    "```bash\n",
    "source ~/mypyenv/bin/activate\n",
    "unset http_proxy https_proxy all_proxy\n",
    "pip install pysocks\n",
    "\n",
    "# close and open a new terminal\n",
    "\n",
    "source ./mypyenv/bin/activate\n",
    "pip install numpy\n",
    "pip3 install torch torchvision torchaudio\n",
    "pip3 install ipykernel\n",
    "```\n",
    "\n",
    "In VSCode\n",
    "\n",
    "Select venv python for python interpreter\n",
    "\n",
    "Create a new file: skip-gram.ipynb\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  ['Xiaobing', 'Student', 'Teacher', 'Boss', 'Mazong', 'Xiaoxue', 'Kage', 'Niuzhong', 'is']\n",
      "From word to index:  {'Xiaobing': 0, 'Student': 1, 'Teacher': 2, 'Boss': 3, 'Mazong': 4, 'Xiaoxue': 5, 'Kage': 6, 'Niuzhong': 7, 'is': 8}\n",
      "From index to word:  {0: 'Xiaobing', 1: 'Student', 2: 'Teacher', 3: 'Boss', 4: 'Mazong', 5: 'Xiaoxue', 6: 'Kage', 7: 'Niuzhong', 8: 'is'}\n",
      "Size of vocabulary:  9\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Kage is Teacher\", \"Mazong is Boss\", \"Niuzhong is Boss\", \"Xiaobing is Student\", \"Xiaoxue is Student\"]\n",
    "words = ' '.join(sentences).split()\n",
    "word_list = list(set(words))\n",
    "word_to_idx = { word: idx for idx, word in enumerate(word_list) }\n",
    "idx_to_word = { idx: word for idx, word in enumerate(word_list) }\n",
    "voc_size = len(word_list)\n",
    "print(\"Vocabulary: \", word_list)\n",
    "print(\"From word to index: \", word_to_idx)\n",
    "print(\"From index to word: \", idx_to_word)\n",
    "print(\"Size of vocabulary: \", voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-Gram data example (Not encoded):  [('Kage', 'Xiaobing'), ('is', 'Xiaobing'), ('Teacher', 'Xiaobing')]\n"
     ]
    }
   ],
   "source": [
    "def create_skipgram_dataset(sentences, window_size=2):\n",
    "    data = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.split()\n",
    "        for idx, word in enumerate(word_list):\n",
    "            for neighbor in sentence[max(idx - window_size, 0):min(idx + window_size + 1, len(sentence))]:\n",
    "                if neighbor != word:\n",
    "                    data.append((neighbor, word))\n",
    "    return data\n",
    "\n",
    "skipgram_data = create_skipgram_dataset(sentences)\n",
    "print(\"Skip-Gram data example (Not encoded): \", skipgram_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word before One-Hot encoding:  Teacher\n",
      "One-Hot encoded vector:  tensor([0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Skip-Gram data example (Encoded):  [(tensor([0., 0., 0., 0., 0., 0., 1., 0., 0.]), 0), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.]), 0), (tensor([0., 0., 1., 0., 0., 0., 0., 0., 0.]), 0)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def one_hot_encoding(word, word_to_idx):\n",
    "    tensor = torch.zeros(len(word_to_idx))\n",
    "    tensor[word_to_idx[word]] = 1\n",
    "    return tensor\n",
    "\n",
    "word_example = \"Teacher\"\n",
    "print(\"Word before One-Hot encoding: \", word_example)\n",
    "print(\"One-Hot encoded vector: \", one_hot_encoding(word_example, word_to_idx))\n",
    "\n",
    "print(\"Skip-Gram data example (Encoded): \", [(one_hot_encoding(context, word_to_idx), word_to_idx[target]) for context, target in skipgram_data[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-Gram class:  SkipGram(\n",
      "  (input_to_hidden): Linear(in_features=9, out_features=2, bias=False)\n",
      "  (hidden_to_output): Linear(in_features=2, out_features=9, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, voc_size, embedding_size):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.input_to_hidden = nn.Linear(voc_size, embedding_size, bias=False)\n",
    "        self.hidden_to_output = nn.Linear(embedding_size, voc_size, bias=False)\n",
    "    def forward(self, X):\n",
    "        hidden = self.input_to_hidden(X)\n",
    "        output = self.hidden_to_output(hidden)\n",
    "        return output\n",
    "\n",
    "embedding_size = 2\n",
    "skipgram_model = SkipGram(voc_size, embedding_size)\n",
    "print(\"Skip-Gram class: \", skipgram_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
